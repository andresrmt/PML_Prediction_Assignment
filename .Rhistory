diagnosis=testing$diagnosis
)
# final predictions on test set:
confusionMatrix(predict(model_rf, testing), testing$diagnosis)$overall[1]
confusionMatrix(predict(model_gbm, testing), testing$diagnosis)$overall[1]
confusionMatrix(predict(model_lda, testing), testing$diagnosis)$overall[1]
confusionMatrix(predict(model_stack, stacked_data_test), testing$diagnosis)$overall[1]
adData   <- data.frame(diagnosis,predictors)
inTrain  <- createDataPartition(adData$diagnosis, p = .7)[[1]]
training <- adData[ inTrain,]
testing  <- adData[-inTrain,]
RNGversion("3.5.3")
set.seed(62433)
stackInTrain <- createDataPartition(training$diagnosis, p=0.7, list=F)
training1 <- training[ stackInTrain,]
training2 <- training[-stackInTrain,]
model_rf  <- train(diagnosis~., training1, method='rf')
model_gbm <- train(diagnosis~., training1, method='gbm')
model_lda <- train(diagnosis~., training1, method='lda')
# prediction on training2
pred_rf  <- predict(model_rf, training2)
pred_gbm <- predict(model_gbm, training2)
pred_lda <- predict(model_lda, training2)
stacked_data <- data.frame(rf_preds=predict(model_rf, training2),
gbm_preds=predict(model_gbm, training2),
lda_preds=predict(model_lda, training2),
diagnosis=training2$diagnosis
)
model_stack <- train(diagnosis~., stacked_data, method='rf')
# testset for stacked clf:
stacked_data_test <- data.frame(rf_preds=predict(model_rf, testing),
gbm_preds=predict(model_gbm, testing),
lda_preds=predict(model_lda, testing),
diagnosis=testing$diagnosis
)
confusionMatrix(predict(model_rf, testing), testing$diagnosis)$overall[1]
confusionMatrix(predict(model_gbm, testing), testing$diagnosis)$overall[1]
confusionMatrix(predict(model_lda, testing), testing$diagnosis)$overall[1]
confusionMatrix(predict(model_stack, stacked_data_test), testing$diagnosis)$overall[1]
RNGversion("3.5.3")
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData   <- data.frame(diagnosis,predictors)
inTrain  <- createDataPartition(adData$diagnosis, p = .6)[[1]]
training <- adData[ inTrain,]
testing  <- adData[-inTrain,]
RNGversion("3.5.3")
set.seed(62433)
stackInTrain <- createDataPartition(training$diagnosis, p=0.6, list=F)
training1 <- training[ stackInTrain,]
training2 <- training[-stackInTrain,]
model_rf  <- train(diagnosis~., training1, method='rf')
model_gbm <- train(diagnosis~., training1, method='gbm')
model_lda <- train(diagnosis~., training1, method='lda')
# prediction on training2
pred_rf  <- predict(model_rf, training2)
pred_gbm <- predict(model_gbm, training2)
pred_lda <- predict(model_lda, training2)
stacked_data <- data.frame(rf_preds  = predict(model_rf, training2),
gbm_preds = predict(model_gbm, training2),
lda_preds = predict(model_lda, training2),
diagnosis = training2$diagnosis
)
model_stack <- train( diagnosis ~ ., stacked_data, method = 'rf')
# testset for stacked clf:
stacked_data_test <- data.frame(rf_preds = predict(model_rf, testing),
gbm_preds = predict(model_gbm, testing),
lda_preds = predict(model_lda, testing),
diagnosis = testing$diagnosis
)
confusionMatrix(predict(model_rf, testing), testing$diagnosis)$overall[1]
confusionMatrix(predict(model_gbm, testing), testing$diagnosis)$overall[1]
confusionMatrix(predict(model_lda, testing), testing$diagnosis)$overall[1]
confusionMatrix(predict(model_stack, stacked_data_test), testing$diagnosis)$overall[1]
RNGversion("3.5.3")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain  = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing  = concrete[-inTrain,]
RNGversion("3.5.3")
set.seed(233)
modFit <- train(CompressiveStrength ~ ., data = training, method = "lasso")
RNGversion("3.5.3")
set.seed(233)
modFit <- train(CompressiveStrength ~ ., data = training, method = "lasso")
modFit
plot.enet
library(AppliedPredictiveModeling); library(elasticnet)
plot.enet(modFit)
plot.enet(modFit$finalModel)
head(training)
modFit$finalModel
coef(modFit)
modFit$coefnames
plot.enet(modFit$finalModel, use.color=T)
plot.enet(modFit$finalModel, use.color=T, xvar="penalty")
aaa<-modFit$finalModel
View(aaa)
plot.enet(modFit$finalModel, use.color=T)#, xvar="penalty")
plot.enet(modFit$finalModel, use.color=T, xvar="penalty")
modFit$finalModel$actions
modFit$finalModel$actions
plot.enet(modFit$finalModel, use.color=T, xvar="penalty")
modFit$finalModel$actions
modFit$finalModel$actions
plot.enet(modFit$finalModel, use.color=T, xvar="penalty")
theURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv"
download.file(theURL, "gaData.csv", mode = "wb")
library(lubridate) # For year() function below
dat      <- read.csv("gaData.csv")
training <- dat[year(dat$date) < 2012,]
testing  <- dat[(year(dat$date)) > 2011,]
tstrain  <- ts(training$visitsTumblr)
library(forecast)
ets1 <- bats(training)
head(training)
training$date <- as.date(training$date)
training$date <- as.Date(training$date)
head(training)
ets1 <- bats(training)
head(training)
dat      <- read.csv("gaData.csv")
dat$date <- as.Date(dat$date)
training <- dat[year(dat$date) < 2012,]
testing  <- dat[(year(dat$date)) > 2011,]
tstrain  <- ts(training$visitsTumblr)
testing
training
ets1 <- bats(tstrain)
ets1
bats_forecast <- forecast(ets1)
bats_forecast
bats_forecast$lower
accuracy(bats_forecast, testing$visitsTumblr)
fcast <- forecast(ets1)
plot(fcast); lines(testing, col = 'red')
testing
fcast$lower
fcast$upper
testing$visitsTumblr
names(fcast$lower)
accuracy(fcast, testing$visitsTumblr)
testing$visitsTumblr < fcast$lower
aaa <- fcast$lower
View(aaa)
aaa[[2]]
aaa[,2
]
as.vector(aaa[,2])
testing$visitsTumblr < fcast$lower[,2]
testing$visitsTumblr < as.vector(fcast$lower[,2])
sum(testing$visitsTumblr < as.vector(fcast$lower[,2]))
testing$visitsTumblr
sum(testing$visitsTumblr > as.vector(fcast$upper[,2]))
17*100/length(testing$visitsTumblr)
100-17*100/length(testing$visitsTumblr)
RNGversion("3.5.3")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain  <- createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training <- concrete[ inTrain,]
testing  <- concrete[-inTrain,]
library(e1071)
RNGversion("3.5.3")
set.seed(325)
modFit <- svm(CompressiveStrength ~ ., data = training)
pred <- predict(modFit, newdata = testing)
#RMSE
sqrt(sum((pred - testing)^2)/length(testing))
sqrt(mean(testing$CompressiveStrength - pred^2))
#RMSE
sqrt(sum((pred - testing$CompressiveStrength)^2)/length(testing))
sqrt(mean((testing$CompressiveStrength - pred)^2))
sum(testing$visitsTumblr < as.vector(fcast$lower[,2]))
sum(testing$visitsTumblr > as.vector(fcast$upper[,2]))
sum(testing$visitsTumblr > as.vector(fcast$upper[,1]))
sum(testing$visitsTumblr < as.vector(fcast$lower[,1]))
sum(testing$visitsTumblr < as.vector(fcast$upper[,2]))
sum( 1*(testing$visitsTumblr < as.vector(fcast$upper[,2])) )
1*(testing$visitsTumblr < as.vector(fcast$upper[,2]))
1*(testing$visitsTumblr > as.vector(fcast$upper[,2]))
sum(testing$visitsTumblr > as.vector(fcast$upper[,2]))
testing$visitsTumblr > as.vector(fcast$upper[,2])
dat      <- read.csv("gaData.csv")
dat$date <- as.Date(dat$date)
training <- dat[year(dat$date) < 2012,]
testing  <- dat[(year(dat$date)) > 2011,]
tstrain  <- ts(training$visitsTumblr)
library(forecast)
ets1 <- bats(tstrain)
fcast <- forecast(ets1)
plot(fcast); lines(testing, col = 'red')
fcast$lower
fcast$upper
testing$visitsTumblr
sum(testing$visitsTumblr < as.vector(fcast$lower[,2]))
sum(testing$visitsTumblr > as.vector(fcast$upper[,2]))
testing$visitsTumblr > as.vector(fcast$upper[,2])
testing$visitsTumblr %in% as.vector(fcast$upper[,2])
testing$visitsTumblr %>% as.vector(fcast$upper[,2])
sum(testing$visitsTumblr > as.vector(fcast$upper[,2]))
testing$visitsTumblr > as.vector(fcast$upper[,2])
1*(testing$visitsTumblr > as.vector(fcast$upper[,2]))
sum(1*(testing$visitsTumblr > as.vector(fcast$upper[,2])))
17*100/length(testing$visitsTumblr)
setwd("~/GitHub/PML_Prediction_Assignment")
knitr::opts_chunk$set(echo = TRUE)
theURL <- 'https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv'
download.file(theURL, 'pml-training.csv', mode = 'wb')
theURL <- 'https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv'
download.file(theURL, 'pml-testing.csv', mode = 'wb')
pml.training <- read.csv('pml-training.csv')
pml.testing  <- read.csv('pml-testing.csv')
str(pml.training)
summary(pml.training)
summary(pml.training$classe)
pml.training$classe
summary(as.factor(pml.training$classe))
summary(factor(pml.training$classe))
summary(factor(pml.training$classe))
sapply(TrainSet, function(x) mean(is.na(x)))
str(pml.training)
View(pml.testing)
pml.testing$max_yaw_dumbbell
nearZeroVar(pml.training)
library(caret)
nearZeroVar(pml.training)
nearZeroVar(pml.training, saveMetrics = T)
summary(nearZeroVar(pml.training, saveMetrics = T))
summary(nearZeroVar(pml.training, saveMetrics = T))
inBuild  <- nearZeroVar(pml.training)
pml.training[, -inBuild]
dim(pml.training[, -inBuild])
dim(pml.training)
inBuild      <- nearZeroVar(pml.training)
pml.training <- pml.training[, -inBuild]
pml.testing  <- pml.testing[ , -inBuild]
sapply(pml.training, function(x) mean(is.na(x))) > 0.95
which(sapply(pml.training, function(x) mean(is.na(x))) > 0.95 == FALSE)
sapply(pml.training, function(x) mean(is.na(x)))
sapply(pml.training, function(x) mean(is.na(x))) > 0.9
sapply(pml.training, function(x) mean(is.na(x))) > 0.9 == FALSE
(sapply(pml.training, function(x) mean(is.na(x))) > 0.9) == FALSE
which((sapply(pml.training, function(x) mean(is.na(x))) > 0.9) == FALSE)
inBuild      <- sapply(pml.training, function(x) mean(is.na(x))) > 0.9
pml.training[, inBuild]
pml.training[, inBuild==FALSE]
dim(pml.training[, inBuild==FALSE])
inBuild      <- which((sapply(pml.training, function(x) mean(is.na(x))) > 0.9) == FALSE)
dim(pml.training[, inBuild])
pml.training[, inBuild]
pml.training <- pml.training[, inBuild]
pml.testing  <- pml.testing[ , inBuild]
160/59
59*3
summary(pml.training)
head(pml.training)
head(pml.training)
inBuild      <- c(1:5)
pml.training <- pml.training[, -inBuild]
pml.testing  <- pml.testing[ , -inBuild]
head(pml.training)
pml.training$new_window
summary(pml.training)
pml.training$classe <- factor(pml.training$classe)
pml.testing$classe  <- factor(pml.testing$classe)
pml.training$classe
factor(pml.testing$classe)
pml.testing$classe
createDataPartition( y = pml.training$classe, p = .6, list = F )
set.seet(4234)
set.seed(4234)
inTrain    <- createDataPartition( y = pml.training$classe, p = .6, list = F )
training   <- buildData[ inTrain,]
training   <- pml.training[ inTrain,]
testing    <- pml.training[-inTrain,]
dim(training)
modFit_1 <- train(classe ~. , method = 'rpart', data = training)
modFit_1
modFit_1$finalModel
modFit_1$modelInfo
pred_1   <- predict(modFit, newdata = testing)
pred_1   <- predict(modFit_1, newdata = testing)
pred_1
library(rattle)
fancyRpartPlot( modFit$finalModel )
fancyRpartPlot( modFit_1$finalModel )
confusionMatrix(pred_1, testing$classe)
modFit_1 <- train(classe ~. , method = 'class', data = training)
rpart
library(rpart); library(rattle)
modFit_1 <- rpart(classe ~. , method = 'class', data = training)
modFit_1
fancyRpartPlot( modFit_1$finalModel )
fancyRpartPlot( modFit_1$ )
fancyRpartPlot( modFit_1 )
pred_1   <- predict(modFit_1, newdata = testing)
confusionMatrix(pred_1, testing$classe)
pred_1
pred_1   <- predict(modFit_1, newdata = testing)
pred_1
pred_1   <- predict(modFit_1, newdata = testing, type="class")
pred_1
confusionMatrix(pred_1, testing$classe)
conf_1 <- confusionMatrix(pred_1, testing$classe)
conf_1
conf_1$table
library(ggplot2)
library(dplyr)
table <- data.frame(conf_1$table)
plotTable <- table %>%
mutate(goodbad = ifelse(table$Prediction == table$Reference, "good", "bad")) %>%
group_by(Reference) %>%
mutate(prop = Freq/sum(Freq))
# fill alpha relative to sensitivity/specificity by proportional outcomes within reference groups (see dplyr code above as well as original confusion matrix for comparison)
ggplot(data = plotTable, mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
geom_tile() +
geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 1) +
scale_fill_manual(values = c(good = "green", bad = "red")) +
theme_bw() +
xlim(rev(levels(table$Reference)))
ggplot(data = plotTable, mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
geom_tile() +
geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 1) +
scale_fill_manual(values = c(good = 'cyan4', bad = "red")) +
theme_bw() +
xlim(rev(levels(table$Reference)))
ggplot(data = plotTable, mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
geom_tile() +
geom_text(aes(label = Freq), vjust = .5, fontface  = "bold", alpha = 1) +
scale_fill_manual(values = c(good = 'cyan4', bad = 'darkgoldenrod1')) +
theme_bw() +
xlim(rev(levels(table$Reference)))
ggplot(data = plotTable, mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
geom_tile() +
geom_text(aes(label = Freq), vjust = .5, fontface  = 'bold', alpha = 1) +
scale_fill_manual(values = c(good = 'cyan4', bad = 'darkgoldenrod1')) +
theme_bw() +
xlim(rev(levels(table$Reference))) +
ggtitle("Confusion")
ggplot(data = plotTable, mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
geom_tile() +
geom_text(aes(label = Freq), vjust = .5, fontface  = 'bold', alpha = 1) +
scale_fill_manual(values = c(good = 'cyan4', bad = 'darkgoldenrod1')) +
theme_bw() +
xlim(rev(levels(table$Reference))) +
ggtitle("Confusion matrix for decision tree model")
conf_1$overall['Accuracy']
conf_1$overall[['Accuracy']]
as.character(conf_1$overall[['Accuracy']])
"Confusion matrix for decision tree model (Acc: " + as.character(conf_1$overall[['Accuracy']])
cat("Confusion matrix for decision tree model (Acc: ", as.character(conf_1$overall[['Accuracy']]))
cat("Confusion matrix for decision tree model \n Accuracy:", as.character(conf_1$overall[['Accuracy']]))
cat("Confusion matrix for decision tree model \nAccuracy:", as.character(conf_1$overall[['Accuracy']]))
conf_1$overall[['Accuracy']]
conf_1$overall[['Accuracy']]*100
100*conf_1$overall[['Accuracy']]
round(100*conf_1$overall[['Accuracy']],2)
round(100*conf_1$overall[['Accuracy']])
cat("Confusion matrix for decision tree model \nAccuracy:",
as.character( round(100*conf_1$overall[['Accuracy']]) ), "%" )
titl_1 <- cat('Confusion matrix for decision tree model \nAccuracy:',
as.character( round(100*conf_1$overall[['Accuracy']]) ), '%' )
ggplot(data = plotTable, mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
geom_tile() +
geom_text(aes(label = Freq), vjust = .5, fontface  = 'bold', alpha = 1) +
scale_fill_manual(values = c(good = 'cyan4', bad = 'darkgoldenrod1')) +
theme_bw() +
xlim(rev(levels(table$Reference))) + ggtitle(titl_1)
titl_1 <- cat('Confusion matrix for decision tree model \nAccuracy:',
as.character( round(100*conf_1$overall[['Accuracy']]) ), '%' )
cat('Confusion matrix for decision tree model \nAccuracy:',
as.character( round(100*conf_1$overall[['Accuracy']]) ), '%' )
titl_1 <- cat('Confusion matrix for decision tree model \nAccuracy:',
as.character( round(100*conf_1$overall[['Accuracy']]) ), '%' )
titl_1
paster('Confusion matrix for decision tree model \nAccuracy:',
as.character( round(100*conf_1$overall[['Accuracy']]) ), '%' )
paster('Confusion matrix for decision tree model \nAccuracy:',
as.character( round(100*conf_1$overall[['Accuracy']]) ) )
paste('Confusion matrix for decision tree model \nAccuracy:',
paste('Confusion matrix for decision tree model \nAccuracy:',
as.character( round(100*conf_1$overall[['Accuracy']]) ), '%' )
titl_1 <- paste('Confusion matrix for decision tree model \nAccuracy:',
as.character( round(100*conf_1$overall[['Accuracy']]) ), '%' )
ggplot(data = plotTable, mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
geom_tile() +
geom_text(aes(label = Freq), vjust = .5, fontface  = 'bold', alpha = 1) +
scale_fill_manual(values = c(good = 'cyan4', bad = 'darkgoldenrod1')) +
theme_bw() +
xlim(rev(levels(table$Reference))) + ggtitle(titl_1)
modFit_2 <- train( classe ~. , data = training, method = 'rf', prox = T )
modFit_2 <- train( classe ~. , data = training, method = 'ranger', prox = T )
rf
modFit_2 <- train( classe ~. , data = training, method = 'rf', prox = T )
library(randomForest)
train(classe ~ ., data = training, method = 'rf',
trControl = trainControl( method = 'boot632', number = 3, verboseIter = F) )
train(classe ~ ., data = training, method = 'rf',
trControl = trainControl( method = 'cv', number = 3, verboseIter = F) )
modFit_2 <- train(classe ~ ., data = training, method = 'rf', prox = T,
trControl = trainControl( method = 'cv', number = 3, verboseIter = F) )
modFit_3  <- train(classe ~ ., data = training, method = 'gbm', verbose = F,
trControl = trainControl(method = 'repeatedcv', number = 3, repeats = 1) )
library(doParallel)
install.packages("doParallel")
library(doParallel)
registerDoParallel()
training[-ncol(training)]
modFit_2 <- train( training$classe, training[-ncol(training)], method="parRF",
tuneGrid=data.frame(mtry=3),
trControl=trainControl(method="none"))
training$classe
class <- training$classe
df    <- training[-ncol(training)]
modFit_2 <- train( class, df, method="parRF",
tuneGrid  = data.frame(mtry=3),
trControl = trainControl(method="none"))
train(classe ~ ., data = training, method = 'parRF',
tuneGrid  = data.frame(mtry=3),
trControl = trainControl(method="none") )
modFit_2 <- train(classe ~ ., data = training, method = 'parRF',
tuneGrid  = data.frame(mtry=3),
trControl = trainControl(method="none") )
modFit_2
pred_2 <- predict(modFit_2, newdata = testing, type = 'class')
plot(varImp(rf))
1
pred_2 <- predict(modFit_2, newdata = testing)
conf_2 <- confusionMatrix(pred_2, testing$classe)
titl_2 <- paste('Confusion matrix for random forest model \nAccuracy:',
as.character( round(100*conf_2$overall[['Accuracy']]) ), '%' )
table  <- data.frame(conf_1$table)
plotTable <- table %>%
mutate(goodbad = ifelse(table$Prediction == table$Reference, 'good', 'bad')) %>%
group_by(Reference) %>%
mutate(prop = Freq/sum(Freq))
ggplot(data = plotTable, mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
geom_tile() +
geom_text(aes(label = Freq), vjust = .5, fontface  = 'bold', alpha = 1) +
scale_fill_manual(values = c(good = 'cyan4', bad = 'darkgoldenrod1')) +
theme_bw() + xlim(rev(levels(table$Reference))) + ggtitle(titl_1)
ggplot(data = plotTable, mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
geom_tile() +
geom_text(aes(label = Freq), vjust = .5, fontface  = 'bold', alpha = 1) +
scale_fill_manual(values = c(good = 'cyan4', bad = 'darkgoldenrod1')) +
theme_bw() + xlim(rev(levels(table$Reference))) + ggtitle(titl_2)
predDF     <- data.frame(pred_1, pred_2, classe = testing$classe)
combModFit <- train(classe ~ ., method = 'gam', data = predDF)
combModFit <- train(classe ~ ., method = 'gam', data = predDF)
combPred   <- predict(combModFit, predDF)
combPred
confusionMatrix(combPred, testing$classe)
pred1V    <- predict(mod1, pml.testing)
pred1V    <- predict(modFit_1, pml.testing)
pred2V    <- predict(modFit_2, pml.testing)
pred1V
pred1V    <- predict(modFit_1, pml.testing, type = 'class')
pred2V
combPredV <- predict(combModFit, predVDF)
predVDF   <- data.frame(pred_1 = pred1V, pred_2 = pred2V)
combPredV <- predict(combModFit, predVDF)
combPredV
confusionMatrix(combPredV, testing$classe)
confusionMatrix(combPredV, pml.testing$classe)
pml.testing
combModFit
combPredV
length(combPredV)
pml.testing$classe
confusionMatrix(combPred, testing$classe)
combModFit <- train(classe ~ ., method = 'rf', data = predDF)
predDF     <- data.frame(pred_1, pred_2, classe = training$classe)
predDF     <- data.frame(pred_1, pred_2, classe = testing$classe)
registerDoParallel()
combModFit <- train(classe ~ ., data = predDF, method = 'parRF',
tuneGrid  = data.frame(mtry=3),
trControl = trainControl(method="none") )
combPred   <- predict(combModFit, newdata = testing )
confusionMatrix(combPred, testing$classe)
conf_2$overall[['Accuracy']]
conf_3 <- confusionMatrix(combPred, testing$classe)
titl_3 <- paste('Confusion matrix for random forest model \nAccuracy:',
as.character( round(100*conf_3$overall[['Accuracy']]) ), '%' )
table  <- data.frame(conf_1$table)
plotTable <- table %>%
mutate(goodbad = ifelse(table$Prediction == table$Reference, 'good', 'bad')) %>%
group_by(Reference) %>%
mutate(prop = Freq/sum(Freq))
ggplot(data = plotTable, mapping = aes(x = Reference, y = Prediction, fill = goodbad, alpha = prop)) +
geom_tile() +
geom_text(aes(label = Freq), vjust = .5, fontface  = 'bold', alpha = 1) +
scale_fill_manual(values = c(good = 'cyan4', bad = 'darkgoldenrod1')) +
theme_bw() + xlim(rev(levels(table$Reference))) + ggtitle(titl_3)
conf_2$overall[['Accuracy']]
conf_2$overall[['Accuracy']] < conf_3$overall[['Accuracy']]
conf_2$overall[['Accuracy']]; conf_3$overall[['Accuracy']]
pred1V    <- predict(modFit_1, pml.testing, type = 'class')
pred2V    <- predict(modFit_2, pml.testing)
predVDF   <- data.frame(pred_1 = pred1V, pred_2 = pred2V)
combPredV <- predict(combModFit, predVDF)
combPredV
pred2V
pred21
pred1
pred1V
combPredV
data.frame(combPredV)
